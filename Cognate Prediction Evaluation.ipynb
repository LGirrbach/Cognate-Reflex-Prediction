{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc03bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from edist import sed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e7a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    \n",
    "    wer = 1 - np.mean([prediction == target for prediction, target in zip(y_pred, y_true)]).item()\n",
    "    edit_distances = [sed.standard_sed(prediction, target) for prediction, target in zip(y_pred, y_true)]\n",
    "    \n",
    "    edit_distance = np.mean(edit_distances).item()\n",
    "    normalised_edit_distance = np.mean(\n",
    "        [distance / len(target) for distance, target in zip(edit_distances, y_true)]\n",
    "    ).item()\n",
    "    \n",
    "    return {\n",
    "        \"wer\": wer,\n",
    "        \"ed\": edit_distance,\n",
    "        \"ned\": normalised_edit_distance\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786a56a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename: str):\n",
    "    filename = filename.split(\".\")[0]\n",
    "    \n",
    "    filename = filename.replace(\"non-autoregressive-lstm\", \"non_autoregressive_lstm\")\n",
    "    filename = filename.replace(\"non-autoregressive-fixed\", \"non_autoregressive_fixed\")\n",
    "    filename = filename.replace(\"non-autoregressive-position\", \"non_autoregressive_position\")\n",
    "    \n",
    "    entries = filename.split(\"-\")[1:]\n",
    "    entries = [tuple(entry.split(\"=\")) for entry in entries]\n",
    "    \n",
    "    return {key: value for key, value in entries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b232fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_path = \"results/evaluation/predictions/\"\n",
    "results = dict()\n",
    "\n",
    "for prediction_file_name in os.listdir(predictions_path):\n",
    "    if not prediction_file_name.endswith(\".pickle\"):\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join(predictions_path, prediction_file_name), \"rb\") as pf:\n",
    "        predictions, targets = pickle.load(pf)\n",
    "        predictions = [prediction.prediction for prediction in predictions]\n",
    "        predictions = [\n",
    "            [symbol for symbol in prediction if not (symbol.startswith(\"<\") or symbol.endswith(\">\"))]\n",
    "            for prediction in predictions\n",
    "        ]\n",
    "    \n",
    "    entry_name = parse_filename(prediction_file_name)\n",
    "    entry_name = tuple([entry_name[key] for key in sorted(entry_name.keys())])\n",
    "    results[entry_name] = get_metrics(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fc01ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('augment_mask_languages', 'augment_shuffle', 'dataset', 'model', 'trial')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_name = parse_filename(prediction_file_name)\n",
    "tuple([key for key in sorted(entry_name.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f586c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('True', 'False', 'felekesemitic', 'non_autoregressive_fixed', '2'),\n",
       " ('True', 'False', 'mannburmish', 'non_autoregressive_position', '3'),\n",
       " ('True', 'False', 'kesslersignificance', 'autoregressive', '4')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(results.keys())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00be3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = list(sorted(set([key[2] for key in results])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69663577",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = list(sorted(set([key[3] for key in results])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0041c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autoregressive',\n",
       " 'non_autoregressive_fixed',\n",
       " 'non_autoregressive_lstm',\n",
       " 'non_autoregressive_position']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1dc0d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bantubvd',\n",
       " 'beidazihui',\n",
       " 'birchallchapacuran',\n",
       " 'bodtkhobwa',\n",
       " 'davletshinaztecan',\n",
       " 'felekesemitic',\n",
       " 'hattorijaponic',\n",
       " 'kesslersignificance',\n",
       " 'listsamplesize',\n",
       " 'luangthongkumkaren',\n",
       " 'mannburmish']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "666b0c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(3.2345, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b209fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_rows(dataset_name: str, metric: str):\n",
    "    def make_row(shuffle: str, mask: str):\n",
    "        shuffle = str(shuffle)\n",
    "        mask = str(mask)\n",
    "        \n",
    "        min_values = []\n",
    "        median_values = []\n",
    "        \n",
    "        for model_name in model_names:\n",
    "            trial_metrics = []\n",
    "            \n",
    "            for trial in range(1, 6):\n",
    "                metrics = results[(mask, shuffle, dataset_name, model_name, str(trial))]\n",
    "                metric_value = metrics[metric]\n",
    "                trial_metrics.append(metric_value)\n",
    "            \n",
    "            min_values.append(min(trial_metrics))\n",
    "            median_values.append(np.median(trial_metrics).item())\n",
    "        \n",
    "        row = []\n",
    "        best_min_value = min(min_values)\n",
    "        best_median_value = min(median_values)\n",
    "        \n",
    "        for min_value, median_value in zip(min_values, median_values):\n",
    "            if min_value == best_min_value:\n",
    "                min_value = f\"{{\\\\color{{red}} \\\\textbf{{{round(min_value, 2)}}}}}\"\n",
    "                # min_value = str(round(min_value, 2))\n",
    "            else:\n",
    "                min_value = str(round(min_value, 2))\n",
    "            \n",
    "            if median_value == best_median_value:\n",
    "                median_value = f\"{{\\\\cellcolor{{blue!25}} {round(median_value, 2)}}}\"\n",
    "                # median_value = str(round(median_value, 2))\n",
    "            else:\n",
    "                median_value = str(round(median_value, 2))\n",
    "            \n",
    "            row.append(f\"{min_value} & {median_value}\")\n",
    "        \n",
    "        return \" & \".join(row)\n",
    "    \n",
    "    rows = []\n",
    "    rows.append(f\"{{\\\\small {dataset_name}}}\" + \" & \" + make_row(False, False))\n",
    "    rows.append(\"\\\\quad + shuffle & \" + make_row(True, False))\n",
    "    rows.append(\"\\\\quad + mask & \" + make_row(False, True))\n",
    "    rows.append(\"\\\\quad + both & \" + make_row(True, True))\n",
    "    \n",
    "    return \"\\\\\\\\ \\n\".join(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d3c02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(metric: str):\n",
    "    table = \"\"\n",
    "    table += \"\\\\begin{tabular}{\" + 4 * 2 * \"c\" + \"} \\n\"\n",
    "    table += \" & \" + \" & \".join([f\"\\\\multicolumn{{2}}{{c}}{{{model_name}}}\" for model_name in model_names])\n",
    "    table += \" \\\\\\\\ \\n\"\n",
    "    table += \" & \" + \" & \".join([\"$\\\\min$. & med.\"] * 4) + \" \\\\\\\\ \\n \\\\midrule \\n\"\n",
    "    \n",
    "    for dataset_name in dataset_names:\n",
    "        table += make_dataset_rows(dataset_name, metric) + \"\\\\\\\\ \\n \\midrule \\n\"\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50977fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = make_table(\"ed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c26fd816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{cccccccc} \n",
      " & \\multicolumn{2}{c}{autoregressive} & \\multicolumn{2}{c}{non_autoregressive_fixed} & \\multicolumn{2}{c}{non_autoregressive_lstm} & \\multicolumn{2}{c}{non_autoregressive_position} \\\\ \n",
      " & $\\min$. & med. & $\\min$. & med. & $\\min$. & med. & $\\min$. & med. \\\\ \n",
      " \\midrule \n",
      "{\\small bantubvd} & 0.96 & 1.0 & 0.89 & {\\cellcolor{blue!25} 0.92} & {\\color{red} \\textbf{0.88}} & 0.99 & 0.97 & 1.01\\\\ \n",
      "\\quad + shuffle & 0.94 & 1.02 & {\\color{red} \\textbf{0.82}} & {\\cellcolor{blue!25} 0.93} & 0.91 & 0.95 & 0.98 & 1.0\\\\ \n",
      "\\quad + mask & 0.9 & 0.93 & 0.85 & 0.9 & 0.85 & 0.91 & {\\color{red} \\textbf{0.84}} & {\\cellcolor{blue!25} 0.88}\\\\ \n",
      "\\quad + both & 0.91 & 0.96 & {\\color{red} \\textbf{0.81}} & {\\cellcolor{blue!25} 0.9} & 0.86 & 0.9 & 0.83 & 0.93\\\\ \n",
      " \\midrule \n",
      "{\\small beidazihui} & 0.49 & 0.51 & 0.48 & {\\cellcolor{blue!25} 0.51} & {\\color{red} \\textbf{0.45}} & 0.53 & 0.5 & 0.52\\\\ \n",
      "\\quad + shuffle & {\\color{red} \\textbf{0.49}} & 0.53 & 0.53 & 0.55 & 0.51 & 0.56 & 0.51 & {\\cellcolor{blue!25} 0.53}\\\\ \n",
      "\\quad + mask & 0.49 & 0.51 & {\\color{red} \\textbf{0.48}} & {\\cellcolor{blue!25} 0.48} & 0.49 & 0.51 & 0.49 & 0.51\\\\ \n",
      "\\quad + both & 0.49 & 0.5 & {\\color{red} \\textbf{0.48}} & {\\cellcolor{blue!25} 0.5} & 0.54 & 0.61 & 0.5 & 0.52\\\\ \n",
      " \\midrule \n",
      "{\\small birchallchapacuran} & 1.97 & 2.27 & 1.71 & 1.88 & {\\color{red} \\textbf{1.55}} & {\\cellcolor{blue!25} 1.76} & 1.73 & 2.04\\\\ \n",
      "\\quad + shuffle & 1.91 & 2.06 & 1.69 & 1.73 & {\\color{red} \\textbf{1.47}} & {\\cellcolor{blue!25} 1.72} & 1.76 & 1.95\\\\ \n",
      "\\quad + mask & 1.95 & 2.02 & 1.54 & 1.61 & 1.54 & {\\cellcolor{blue!25} 1.55} & {\\color{red} \\textbf{1.49}} & 1.78\\\\ \n",
      "\\quad + both & 1.88 & 2.03 & 1.61 & 1.66 & {\\color{red} \\textbf{1.46}} & {\\cellcolor{blue!25} 1.59} & 1.53 & 1.65\\\\ \n",
      " \\midrule \n",
      "{\\small bodtkhobwa} & {\\color{red} \\textbf{0.32}} & {\\cellcolor{blue!25} 0.34} & 0.34 & 0.34 & 0.37 & 0.39 & 0.34 & 0.35\\\\ \n",
      "\\quad + shuffle & 0.43 & 0.45 & {\\color{red} \\textbf{0.39}} & 0.42 & 0.41 & {\\cellcolor{blue!25} 0.41} & 0.4 & 0.42\\\\ \n",
      "\\quad + mask & 0.4 & 0.42 & 0.39 & 0.41 & 0.4 & 0.4 & {\\color{red} \\textbf{0.36}} & {\\cellcolor{blue!25} 0.38}\\\\ \n",
      "\\quad + both & 0.43 & 0.46 & {\\color{red} \\textbf{0.4}} & {\\cellcolor{blue!25} 0.42} & 0.41 & 0.44 & 0.42 & 0.47\\\\ \n",
      " \\midrule \n",
      "{\\small davletshinaztecan} & 1.95 & 2.15 & 2.0 & {\\cellcolor{blue!25} 2.03} & {\\color{red} \\textbf{1.89}} & 2.06 & 1.97 & 2.15\\\\ \n",
      "\\quad + shuffle & 1.96 & 2.24 & 1.97 & 1.98 & 1.9 & 2.03 & {\\color{red} \\textbf{1.88}} & {\\cellcolor{blue!25} 1.96}\\\\ \n",
      "\\quad + mask & 1.9 & 2.02 & {\\color{red} \\textbf{1.81}} & {\\cellcolor{blue!25} 1.96} & 1.83 & 2.02 & 2.01 & 2.05\\\\ \n",
      "\\quad + both & 1.92 & 2.01 & 1.88 & 2.3 & {\\color{red} \\textbf{1.85}} & {\\cellcolor{blue!25} 1.87} & 1.96 & 1.99\\\\ \n",
      " \\midrule \n",
      "{\\small felekesemitic} & 1.57 & 1.73 & {\\color{red} \\textbf{1.4}} & 1.51 & 1.44 & {\\cellcolor{blue!25} 1.5} & 1.62 & 1.71\\\\ \n",
      "\\quad + shuffle & 1.73 & 1.8 & 1.45 & {\\cellcolor{blue!25} 1.46} & {\\color{red} \\textbf{1.42}} & 1.49 & 1.5 & 1.55\\\\ \n",
      "\\quad + mask & 1.63 & 1.72 & 1.39 & {\\cellcolor{blue!25} 1.42} & {\\color{red} \\textbf{1.36}} & {\\cellcolor{blue!25} 1.42} & 1.41 & 1.46\\\\ \n",
      "\\quad + both & 1.61 & 1.72 & 1.42 & 1.49 & 1.4 & {\\cellcolor{blue!25} 1.45} & {\\color{red} \\textbf{1.39}} & 1.51\\\\ \n",
      " \\midrule \n",
      "{\\small hattorijaponic} & 0.84 & 0.92 & {\\color{red} \\textbf{0.77}} & {\\cellcolor{blue!25} 0.87} & 0.86 & 0.88 & 0.86 & 0.89\\\\ \n",
      "\\quad + shuffle & 0.87 & 0.96 & 0.8 & 0.81 & {\\color{red} \\textbf{0.77}} & {\\cellcolor{blue!25} 0.8} & 0.85 & 0.9\\\\ \n",
      "\\quad + mask & 0.81 & 0.88 & 0.77 & 0.8 & {\\color{red} \\textbf{0.75}} & {\\cellcolor{blue!25} 0.8} & 0.81 & 0.85\\\\ \n",
      "\\quad + both & 0.9 & 0.93 & {\\color{red} \\textbf{0.78}} & 0.84 & 0.8 & 0.83 & 0.81 & {\\cellcolor{blue!25} 0.82}\\\\ \n",
      " \\midrule \n",
      "{\\small kesslersignificance} & 2.48 & 2.63 & {\\color{red} \\textbf{2.46}} & {\\cellcolor{blue!25} 2.59} & 2.6 & 2.68 & 2.57 & 2.7\\\\ \n",
      "\\quad + shuffle & {\\color{red} \\textbf{2.49}} & {\\cellcolor{blue!25} 2.58} & 2.53 & 2.7 & 2.55 & 2.65 & 2.56 & 2.69\\\\ \n",
      "\\quad + mask & 2.58 & 2.74 & 2.46 & 2.6 & 2.45 & {\\cellcolor{blue!25} 2.57} & {\\color{red} \\textbf{2.39}} & {\\cellcolor{blue!25} 2.57}\\\\ \n",
      "\\quad + both & {\\color{red} \\textbf{2.49}} & 2.66 & {\\color{red} \\textbf{2.49}} & 2.59 & 2.54 & {\\cellcolor{blue!25} 2.56} & 2.51 & 2.6\\\\ \n",
      " \\midrule \n",
      "{\\small listsamplesize} & 2.34 & 2.51 & 2.37 & 2.49 & {\\color{red} \\textbf{2.28}} & 2.46 & {\\color{red} \\textbf{2.28}} & {\\cellcolor{blue!25} 2.44}\\\\ \n",
      "\\quad + shuffle & {\\color{red} \\textbf{2.33}} & 2.55 & 2.35 & 2.48 & 2.34 & {\\cellcolor{blue!25} 2.38} & 2.34 & 2.52\\\\ \n",
      "\\quad + mask & 2.3 & 2.53 & 2.23 & {\\cellcolor{blue!25} 2.29} & {\\color{red} \\textbf{2.13}} & 2.35 & 2.25 & 2.32\\\\ \n",
      "\\quad + both & 2.53 & 2.59 & 2.33 & 2.42 & {\\color{red} \\textbf{2.22}} & 2.4 & 2.29 & {\\cellcolor{blue!25} 2.37}\\\\ \n",
      " \\midrule \n",
      "{\\small luangthongkumkaren} & {\\color{red} \\textbf{0.29}} & 0.31 & 0.3 & {\\cellcolor{blue!25} 0.31} & 0.3 & 0.34 & 0.36 & 0.36\\\\ \n",
      "\\quad + shuffle & {\\color{red} \\textbf{0.31}} & {\\cellcolor{blue!25} 0.33} & 0.33 & 0.38 & 0.34 & 0.38 & 0.39 & 0.39\\\\ \n",
      "\\quad + mask & {\\color{red} \\textbf{0.32}} & {\\cellcolor{blue!25} 0.33} & 0.35 & 0.38 & 0.33 & 0.34 & 0.37 & 0.38\\\\ \n",
      "\\quad + both & {\\color{red} \\textbf{0.32}} & 0.33 & 0.38 & 0.4 & 0.33 & {\\cellcolor{blue!25} 0.33} & 0.38 & 0.41\\\\ \n",
      " \\midrule \n",
      "{\\small mannburmish} & 1.75 & 1.83 & {\\color{red} \\textbf{1.68}} & {\\cellcolor{blue!25} 1.69} & {\\color{red} \\textbf{1.68}} & 1.78 & 1.73 & 1.8\\\\ \n",
      "\\quad + shuffle & 1.71 & 1.84 & {\\color{red} \\textbf{1.57}} & {\\cellcolor{blue!25} 1.63} & 1.66 & 1.67 & 1.61 & 1.73\\\\ \n",
      "\\quad + mask & 1.8 & 1.81 & 1.6 & 1.68 & {\\color{red} \\textbf{1.52}} & 1.68 & 1.59 & {\\cellcolor{blue!25} 1.65}\\\\ \n",
      "\\quad + both & 1.8 & 1.82 & 1.63 & 1.69 & {\\color{red} \\textbf{1.6}} & 1.62 & {\\color{red} \\textbf{1.6}} & {\\cellcolor{blue!25} 1.62}\\\\ \n",
      " \\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2244e970",
   "metadata": {},
   "source": [
    "## Get best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18c7987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from cognate_prediction_experiment import get_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cbb04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = get_hyperparameters()\n",
    "model_names = list(sorted(hyperparameters.keys()))\n",
    "\n",
    "hyperparameter_table = pd.DataFrame.from_records(\n",
    "    [\n",
    "        {\n",
    "            key: (round(val, 4) if isinstance(val, float) else val)\n",
    "            for key, val in hyperparameters[model_name].items()\n",
    "        } \n",
    "        for model_name in model_names\n",
    "    ],\n",
    "    index=model_names\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a97b222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  autoregressive &  non-autoregressive-fixed &  non-autoregressive-lstm &  non-autoregressive-position \\\\\n",
      "\\midrule\n",
      "batch\\_size  &         16.0000 &                    5.0000 &                  22.0000 &                      22.0000 \\\\\n",
      "dropout     &          0.3726 &                    0.2831 &                   0.2933 &                       0.3884 \\\\\n",
      "epochs      &         28.0000 &                   26.0000 &                  37.0000 &                      37.0000 \\\\\n",
      "gamma       &          0.9504 &                    0.9116 &                   0.9034 &                       0.9445 \\\\\n",
      "hidden\\_size &        367.0000 &                  157.0000 &                 353.0000 &                     176.0000 \\\\\n",
      "lr          &          0.0015 &                    0.0013 &                   0.0016 &                       0.0027 \\\\\n",
      "num\\_layers  &          1.0000 &                    1.0000 &                   1.0000 &                       1.0000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6354/2328693338.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(hyperparameter_table.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(hyperparameter_table.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c5ca9",
   "metadata": {},
   "source": [
    "## Get Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5294bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_scores = {model_type.replace(\"-\", \"_\"): 0 for model_type in  model_names}\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for do_mask in [str(False), str(True)]:\n",
    "        for do_shuffle in [str(False), str(True)]:\n",
    "            for i, model_name_1 in enumerate(model_names):\n",
    "                model_name_1 = model_name_1.replace(\"-\", \"_\")\n",
    "                for model_name_2 in model_names[i+1:]:\n",
    "                    model_name_2 = model_name_2.replace(\"-\", \"_\")\n",
    "                    \n",
    "                    for trial_1 in range(1, 6):\n",
    "                        for trial_2 in range(1, 6):\n",
    "                            score_1 = results[(do_shuffle, do_mask, dataset_name, model_name_1, str(trial_1))]\n",
    "                            score_1 = score_1[\"ed\"]\n",
    "                            \n",
    "                            score_2 = results[(do_shuffle, do_mask, dataset_name, model_name_2, str(trial_2))]\n",
    "                            score_2 = score_2[\"ed\"]\n",
    "                            \n",
    "                            if score_1 < score_2:\n",
    "                                ranking_scores[model_name_1] += 1\n",
    "                                ranking_scores[model_name_2] -= 1\n",
    "                            elif score_1 > score_2:\n",
    "                                ranking_scores[model_name_1] -= 1\n",
    "                                ranking_scores[model_name_2] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7575456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'autoregressive': -1124,\n",
       " 'non_autoregressive_fixed': 593,\n",
       " 'non_autoregressive_lstm': 726,\n",
       " 'non_autoregressive_position': -195}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef5370",
   "metadata": {},
   "source": [
    "## Data Augmentation Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2427a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a555ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_to_method_name(shuffle, mask):\n",
    "    if shuffle and mask:\n",
    "        return \"both\"\n",
    "    elif shuffle and not mask:\n",
    "        return \"shuffle\"\n",
    "    elif not shuffle and mask:\n",
    "        return \"mask\"\n",
    "    else:\n",
    "        return \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3202b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_gains = {\n",
    "    params_to_method_name(shuffle, mask): {model_name.replace(\"-\", \"_\"): [] for model_name in model_names}\n",
    "    for shuffle, mask in product([False, True], [False, True])\n",
    "}\n",
    "\n",
    "perc_gains = {\n",
    "    params_to_method_name(shuffle, mask): {model_name.replace(\"-\", \"_\"): [] for model_name in model_names}\n",
    "    for shuffle, mask in product([False, True], [False, True])\n",
    "}\n",
    "\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for do_mask in [False, True]:\n",
    "        for do_shuffle in [False, True]:\n",
    "            for model_name in model_names:\n",
    "                model_name = model_name.replace(\"-\", \"_\")\n",
    "                \n",
    "                baseline_score = np.mean(\n",
    "                    [results[(str(False), str(False), dataset_name, model_name, str(trial))][\"ed\"]\n",
    "                     for trial in range(1, 6)\n",
    "                    ]\n",
    "                )\n",
    "                augmentation_score = np.mean(\n",
    "                    [results[(str(do_mask), str(do_shuffle), dataset_name, model_name, str(trial))][\"ed\"]\n",
    "                     for trial in range(1, 6)\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                diff = augmentation_score - baseline_score\n",
    "                perc = ((baseline_score - augmentation_score) / baseline_score) * 100\n",
    "                \n",
    "                abs_gains[params_to_method_name(do_shuffle, do_mask)][model_name].append(diff)\n",
    "                perc_gains[params_to_method_name(do_shuffle, do_mask)][model_name].append(perc)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34c22455",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_techniques = list(sorted(abs_gains.keys()))\n",
    "augmentation_table = dict()\n",
    "\n",
    "for technique in augmentation_techniques:\n",
    "    augmentation_table[technique + \"+ abs\"] = dict()\n",
    "    # augmentation_table[technique + \"+ perc\"] = dict()\n",
    "\n",
    "for technique in augmentation_techniques:\n",
    "    for model_name in model_names:\n",
    "        augmentation_table[technique + \"+ abs\"][model_name] = np.mean(\n",
    "            abs_gains[technique][model_name.replace(\"-\", \"_\")]\n",
    "        )\n",
    "        # augmentation_table[technique + \"+ perc\"][model_name] = np.mean(\n",
    "        #    perc_gains[technique][model_name.replace(\"-\", \"_\")]\n",
    "        #)\n",
    "\n",
    "augmentation_table = pd.DataFrame.from_dict(augmentation_table).T.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "376bf0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  autoregressive &  non-autoregressive-fixed &  non-autoregressive-lstm &  non-autoregressive-position \\\\\n",
      "\\midrule\n",
      "both+ abs    &          -0.007 &                    -0.012 &                   -0.062 &                       -0.090 \\\\\n",
      "mask+ abs    &          -0.006 &                    -0.060 &                   -0.077 &                       -0.108 \\\\\n",
      "none+ abs    &           0.000 &                     0.000 &                    0.000 &                        0.000 \\\\\n",
      "shuffle+ abs &           0.038 &                    -0.003 &                   -0.014 &                       -0.026 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6354/1481738486.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(augmentation_table.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(augmentation_table.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e59d1",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d74ef384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cf3602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file_name = \"cognates-model=non-autoregressive-lstm-dataset=listsamplesize-augment_shuffle=False\"\n",
    "pred_file_name = pred_file_name + \"-augment_mask_languages=True-trial=1.pickle\"\n",
    "\n",
    "pred_file_name = f\"results/evaluation/predictions/{pred_file_name}\"\n",
    "\n",
    "with open(pred_file_name, \"rb\") as pf:\n",
    "    predictions = pickle.load(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cc0347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mother_pred = predictions[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "821cf9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransducerPrediction(prediction=['<SOS>', 'm', 'ɔ', 'd', 'ə', 'r', '<EOS>'], alignment=[AlignmentPosition(symbol=['<SOS>', '<SOS>', '<SOS>'], actions=[<actions.Substitution object at 0x7f79c097c490>], predictions=['<SOS>']), AlignmentPosition(symbol=['m', 'm', 'm'], actions=[<actions.Substitution object at 0x7f79c07cf280>], predictions=['m']), AlignmentPosition(symbol=['ʌ', 'ɛ', 'ʊ'], actions=[<actions.Substitution object at 0x7f79c07e89a0>], predictions=['ɔ']), AlignmentPosition(symbol=['ð', '-', 't'], actions=[<actions.Substitution object at 0x7f79c07e86a0>], predictions=['d']), AlignmentPosition(symbol=['ə', '-', 'ə'], actions=[<actions.Substitution object at 0x7f79c07e8970>], predictions=['ə']), AlignmentPosition(symbol=['r', 'ʀ', 'r'], actions=[<actions.Substitution object at 0x7f79c07e8610>], predictions=['r']), AlignmentPosition(symbol=['<EOS>', '<EOS>', '<EOS>'], actions=[<actions.Substitution object at 0x7f79c07e8220>], predictions=['<EOS>'])])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mother_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8528db19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & m & uː & d & ə & r\n",
      " & m & ɔ & d & ə & r\n",
      "\n",
      " & m & ʌ & ð & ə & r\n",
      " & m & ɛ & - & - & ʀ\n",
      " & m & ʊ & t & ə & r\n"
     ]
    }
   ],
   "source": [
    "pred = \"\"\n",
    "source = [\"\", \"\", \"\"]\n",
    "\n",
    "for position in mother_pred.alignment[1:-1]:\n",
    "    pred = pred + \" & \" + \" \".join(position.predictions)\n",
    "    \n",
    "    for i, symbol in enumerate(position.symbol):\n",
    "        source[i] = source[i] + \" & \" + symbol\n",
    "\n",
    "print(\" & m & uː & d & ə & r\")\n",
    "print(pred)\n",
    "print()\n",
    "for s in source:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdb5205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & b & a & ʀ &  b\n",
      " & b & ɑ̃ & ʀ &  & t\n",
      "\n",
      " & b & aː & r & - & t\n",
      " & b & ɪ & - & ə & d\n",
      " & b & aː & r & - & t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "horn_pred = predictions[0][122]\n",
    "\n",
    "pred = \"\"\n",
    "source = [\"\", \"\", \"\", \"\"]\n",
    "\n",
    "for position in horn_pred.alignment[1:-1]:\n",
    "    pred = pred + \" & \" + \" \".join(position.predictions)\n",
    "    \n",
    "    for i, symbol in enumerate(position.symbol):\n",
    "        source[i] = source[i] + \" & \" + symbol\n",
    "\n",
    "print(\" & b & a & ʀ &  b\")\n",
    "print(pred)\n",
    "print()\n",
    "for s in source:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e42baa",
   "metadata": {},
   "source": [
    "## Multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8aa831e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(dataset_name: str):\n",
    "    with open(f\"data/{dataset_name}/solutions-0.10.tsv\") as tf:\n",
    "        test_targets = []\n",
    "        for line in tf:\n",
    "            entries = line.strip().split(\"\\t\")\n",
    "            entries = [entry.strip() for entry in entries if entry.strip()]\n",
    "            if len(entries) == 2:\n",
    "                test_targets.append(entries[1].split())\n",
    "        return test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5782d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_path = \"results/multilingual/predictions/\"\n",
    "results = dict()\n",
    "\n",
    "for prediction_file_name in os.listdir(predictions_path):\n",
    "    if not prediction_file_name.endswith(\".pickle\"):\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join(predictions_path, prediction_file_name), \"rb\") as pf:\n",
    "        predictions, _ = pickle.load(pf)\n",
    "        predictions = [prediction.prediction for prediction in predictions]\n",
    "        predictions = [\n",
    "            [symbol for symbol in prediction if not (symbol.startswith(\"<\") or symbol.endswith(\">\"))]\n",
    "            for prediction in predictions\n",
    "        ]\n",
    "    \n",
    "    entry_name = parse_filename(prediction_file_name)\n",
    "    entry_name = tuple([entry_name[key] for key in sorted(entry_name.keys())])\n",
    "    targets = get_targets(entry_name[2])\n",
    "    \n",
    "    results[entry_name] = get_metrics(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25c776d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(\n",
    "    index=dataset_names,\n",
    "    columns=pd.MultiIndex.from_tuples(list(product(model_names, [\"min\", \"median\"])))\n",
    ")\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for model_name in model_names:\n",
    "        scores = [\n",
    "            results[(\"True\", \"False\", dataset_name, model_name.replace(\"-\", \"_\"), str(trial))][\"ed\"]\n",
    "            for trial in range(1, 6)\n",
    "        ]\n",
    "        table.loc[dataset_name][(model_name, \"min\")] = round(np.min(scores).item(), 2)\n",
    "        table.loc[dataset_name][(model_name, \"median\")] = round(np.median(scores).item(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95d7024e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">autoregressive</th>\n",
       "      <th colspan=\"2\" halign=\"left\">non-autoregressive-fixed</th>\n",
       "      <th colspan=\"2\" halign=\"left\">non-autoregressive-lstm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">non-autoregressive-position</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bantubvd</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beidazihui</th>\n",
       "      <td>0.472</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birchallchapacuran</th>\n",
       "      <td>1.701</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.505</td>\n",
       "      <td>1.565</td>\n",
       "      <td>1.451</td>\n",
       "      <td>1.554</td>\n",
       "      <td>1.647</td>\n",
       "      <td>1.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodtkhobwa</th>\n",
       "      <td>0.395</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>davletshinaztecan</th>\n",
       "      <td>1.926</td>\n",
       "      <td>2.046</td>\n",
       "      <td>1.861</td>\n",
       "      <td>1.917</td>\n",
       "      <td>1.852</td>\n",
       "      <td>1.935</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felekesemitic</th>\n",
       "      <td>1.426</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.361</td>\n",
       "      <td>1.421</td>\n",
       "      <td>1.474</td>\n",
       "      <td>1.487</td>\n",
       "      <td>1.363</td>\n",
       "      <td>1.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hattorijaponic</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kesslersignificance</th>\n",
       "      <td>2.475</td>\n",
       "      <td>2.545</td>\n",
       "      <td>2.434</td>\n",
       "      <td>2.515</td>\n",
       "      <td>2.525</td>\n",
       "      <td>2.545</td>\n",
       "      <td>2.434</td>\n",
       "      <td>2.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listsamplesize</th>\n",
       "      <td>2.119</td>\n",
       "      <td>2.175</td>\n",
       "      <td>2.222</td>\n",
       "      <td>2.247</td>\n",
       "      <td>2.098</td>\n",
       "      <td>2.186</td>\n",
       "      <td>2.216</td>\n",
       "      <td>2.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luangthongkumkaren</th>\n",
       "      <td>0.316</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mannburmish</th>\n",
       "      <td>1.635</td>\n",
       "      <td>1.741</td>\n",
       "      <td>1.724</td>\n",
       "      <td>1.759</td>\n",
       "      <td>1.542</td>\n",
       "      <td>1.544</td>\n",
       "      <td>1.739</td>\n",
       "      <td>1.808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    autoregressive        non-autoregressive-fixed         \\\n",
       "                               min median                      min median   \n",
       "bantubvd                     0.859  0.935                    0.819  0.839   \n",
       "beidazihui                   0.472  0.504                    0.571  0.581   \n",
       "birchallchapacuran           1.701   1.75                    1.505  1.565   \n",
       "bodtkhobwa                   0.395  0.405                    0.448  0.452   \n",
       "davletshinaztecan            1.926  2.046                    1.861  1.917   \n",
       "felekesemitic                1.426   1.45                    1.361  1.421   \n",
       "hattorijaponic               0.843  0.904                    0.846  0.868   \n",
       "kesslersignificance          2.475  2.545                    2.434  2.515   \n",
       "listsamplesize               2.119  2.175                    2.222  2.247   \n",
       "luangthongkumkaren           0.316  0.368                    0.411  0.438   \n",
       "mannburmish                  1.635  1.741                    1.724  1.759   \n",
       "\n",
       "                    non-autoregressive-lstm         \\\n",
       "                                        min median   \n",
       "bantubvd                              0.758  0.819   \n",
       "beidazihui                            0.445  0.455   \n",
       "birchallchapacuran                    1.451  1.554   \n",
       "bodtkhobwa                             0.37  0.376   \n",
       "davletshinaztecan                     1.852  1.935   \n",
       "felekesemitic                         1.474  1.487   \n",
       "hattorijaponic                          0.7  0.768   \n",
       "kesslersignificance                   2.525  2.545   \n",
       "listsamplesize                        2.098  2.186   \n",
       "luangthongkumkaren                    0.306  0.322   \n",
       "mannburmish                           1.542  1.544   \n",
       "\n",
       "                    non-autoregressive-position         \n",
       "                                            min median  \n",
       "bantubvd                                   0.81  0.903  \n",
       "beidazihui                                0.578  0.591  \n",
       "birchallchapacuran                        1.647  1.652  \n",
       "bodtkhobwa                                0.459  0.478  \n",
       "davletshinaztecan                          1.88  2.046  \n",
       "felekesemitic                             1.363  1.382  \n",
       "hattorijaponic                            0.843  0.907  \n",
       "kesslersignificance                       2.434  2.535  \n",
       "listsamplesize                            2.216  2.232  \n",
       "luangthongkumkaren                        0.474  0.503  \n",
       "mannburmish                               1.739  1.808  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd4544a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{autoregressive} & \\multicolumn{2}{l}{non-autoregressive-fixed} & \\multicolumn{2}{l}{non-autoregressive-lstm} & \\multicolumn{2}{l}{non-autoregressive-position} \\\\\n",
      "{} &            min & median &                      min & median &                     min & median &                         min & median \\\\\n",
      "\\midrule\n",
      "bantubvd            &           0.86 &   0.94 &                     0.82 &   0.84 &                    0.76 &   0.82 &                        0.81 &    0.9 \\\\\n",
      "beidazihui          &           0.47 &    0.5 &                     0.57 &   0.58 &                    0.45 &   0.46 &                        0.58 &   0.59 \\\\\n",
      "birchallchapacuran  &            1.7 &   1.75 &                     1.51 &   1.57 &                    1.45 &   1.55 &                        1.65 &   1.65 \\\\\n",
      "bodtkhobwa          &            0.4 &    0.4 &                     0.45 &   0.45 &                    0.37 &   0.38 &                        0.46 &   0.48 \\\\\n",
      "davletshinaztecan   &           1.93 &   2.05 &                     1.86 &   1.92 &                    1.85 &   1.94 &                        1.88 &   2.05 \\\\\n",
      "felekesemitic       &           1.43 &   1.45 &                     1.36 &   1.42 &                    1.47 &   1.49 &                        1.36 &   1.38 \\\\\n",
      "hattorijaponic      &           0.84 &    0.9 &                     0.85 &   0.87 &                     0.7 &   0.77 &                        0.84 &   0.91 \\\\\n",
      "kesslersignificance &           2.47 &   2.55 &                     2.43 &   2.52 &                    2.53 &   2.55 &                        2.43 &   2.54 \\\\\n",
      "listsamplesize      &           2.12 &   2.18 &                     2.22 &   2.25 &                     2.1 &   2.19 &                        2.22 &   2.23 \\\\\n",
      "luangthongkumkaren  &           0.32 &   0.37 &                     0.41 &   0.44 &                    0.31 &   0.32 &                        0.47 &    0.5 \\\\\n",
      "mannburmish         &           1.64 &   1.74 &                     1.72 &   1.76 &                    1.54 &   1.54 &                        1.74 &   1.81 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6354/3293683267.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(table.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(table.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
